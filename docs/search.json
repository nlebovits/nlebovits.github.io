[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nissim Lebovits",
    "section": "",
    "text": "I am a Fulbright research fellow based in La Plata, Argentina, where I am investigating opportunities to use open source satellite imagery to improve local flood risk modeling. I have a master’s degree in city planning from the University of Pennsylvania’s Weitzman School of Design, where I focused on environmental planning and geospatial data science.\nPreviously, I worked as a research assistant for Professor Allison Lassiter. We built a clustering model to identify vulnerable U.S. public drinking water systems, and worked on a multi-agent system simulation of how saltwater intrusion might affect coastal drinking water supply networks. With Professor Matthijs Bouw, I also developed flooding and heat models for a UN-Habitat project that will help urban planners in the global south mitigate conflicts between urban expansion, climate threats, and biodiversity loss.\nI am the founder of Clean & Green Philly, an open source, nonprofit tech platform that promotes data-driven interventions in vacant properties to improve quality of life in Philadelphia.\nI’m interested in using data to foster civic engagement and build more sustainable, inclusive cities. I believe in open-source tech and community-driven work. Check out my work to see what I’ve been up to lately."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Work",
    "section": "",
    "text": "Análisis de datos de incendios en Villa del Rosario\n\n\n\n\n\n\n\n\n\nSep 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeminario UBA: Datos abiertos para ciudades sustentables\n\n\n\n\n\n\n\n\n\nJun 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOp Ed: Use Data for Better Cleaning and Greening\n\n\n\n\n\n\n\n\n\nOct 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoogle Earth Engine for Urban Planning\n\n\n\n\n\n\n\n\n\nMar 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemote Sensing for Urban Planning\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClean & Green Philly\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Upzoning Opportunities\n\n\n\n\n\n\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlood Prediction for Costa Rica\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWetland Change in Argentina\n\n\n\n\n\n\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Illegal Dumping\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Vulnerable Water Suppliers\n\n\n\n\n\n\n\n\n\nJan 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSea Level Rise Threat to Biodiversity\n\n\n\n\n\n\n\n\n\nDec 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllegal Dumping Live Dashboard\n\n\n\n\n\n\n\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/upzoning/index.html",
    "href": "posts/upzoning/index.html",
    "title": "Identifying Upzoning Opportunities",
    "section": "",
    "text": "For a “Public Policy Analytics” class at Penn, Laura Frances and I analyzed conflicts between anticipated and current zoning. Using a random forest model trained on historic Philadelphia construction permits, we identified areas of the city with restrictive zoning that would potentially hinder anticipated residential development. We then considered how the model could be used to inform efforts at zoning reform and more strategic planning meant to alleviate issues of housing affordability across Philadelphia."
  },
  {
    "objectID": "posts/illegal_dumping_dashboard/index.html",
    "href": "posts/illegal_dumping_dashboard/index.html",
    "title": "Illegal Dumping Live Dashboard",
    "section": "",
    "text": "To improve my R skills, I built a dashboard in R that uses flexdashboard to visualize illegal dumping in Philadelphia. The dashboard is interactive and allows users to choose different layers to visualize. It pulls data from the City’s Carto database and automates daily updates with a cron job."
  },
  {
    "objectID": "posts/seminario_uba/index.html#actividad-1",
    "href": "posts/seminario_uba/index.html#actividad-1",
    "title": "Seminario UBA: Datos abiertos para ciudades sustentables",
    "section": "Actividad 1",
    "text": "Actividad 1\n\nSeleccionar uno de los siguientes portales de datos abiertos:\n\nPortal de Datos Abiertos de Buenos Aires\nGeoportal de Obras Públicas\nGoogle Earth Engine Datasets\n\nBuscar datos que te interesen\nCompartir con un compañero de clase:\n\n¿Qué datos encontraste?\n¿Por qué te interesaron?\n¿Viste algo que te llamó la atención?"
  },
  {
    "objectID": "posts/seminario_uba/index.html#actividad-2",
    "href": "posts/seminario_uba/index.html#actividad-2",
    "title": "Seminario UBA: Datos abiertos para ciudades sustentables",
    "section": "Actividad 2",
    "text": "Actividad 2\n\nSeleccionar uno de los siguientes recursos:\n\nInfografías de Impacto y Casos de Uso - datos.gob.es\nKit de Herramientas de Datos Abiertos - Banco Mundial\nEjemplos de Uso - Biblioteca del Congreso Nacional de Chile\n\nBuscar una aplicación de datos abiertos que te resulte interesante\nCompartir con un compañero de clase:\n\n¿Cuál es el caso de uso?\n¿Qué datos utilizaron?\n¿Por qué te resultó interesante?"
  },
  {
    "objectID": "posts/seminario_uba/index.html#taller",
    "href": "posts/seminario_uba/index.html#taller",
    "title": "Seminario UBA: Datos abiertos para ciudades sustentables",
    "section": "Taller",
    "text": "Taller\nPara el taller, por favor hagan una copia propia de este cuaderno de Google Colab.\nDespués del taller, voy a subir acá las soluciones a los ejercicios."
  },
  {
    "objectID": "posts/seminario_uba/index.html#información-de-contacto",
    "href": "posts/seminario_uba/index.html#información-de-contacto",
    "title": "Seminario UBA: Datos abiertos para ciudades sustentables",
    "section": "Información de contacto",
    "text": "Información de contacto\n\nnissimlebovits [arroba] proton [punto] me\nDatos a escala humana (blog)"
  },
  {
    "objectID": "posts/seminario_uba/index.html#slides",
    "href": "posts/seminario_uba/index.html#slides",
    "title": "Seminario UBA: Datos abiertos para ciudades sustentables",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "posts/ebird/index.html",
    "href": "posts/ebird/index.html",
    "title": "Sea Level Rise Threat to Biodiversity",
    "section": "",
    "text": "For a floodplain management class in my first semester at Penn, I was interested in using citizen science data from eBird to explore conflicts between biodiversity and sea level rise. Follow the Cornell Ornithology Lab’s workflows for eBird data in R, I explored different ways of aggregating bird observations to a hex grid in Philadelphia, including trying to account for anomalous observations during COVID. Then I compared these data to projected NOAA sea level rise scenarios. I identified the John Heinz National Wildlife Refuge, Pennypack on the Delaware, and Bartram’s Garden as areas facing a particularly high threat by sea level rise to biodiversity. I also suggested that future efforts along these lines should focus on improving on the statistical rigor of this analysis and standardizing a streamlined workflow to allow for replication in Philadelphia and other cities, while also striving to interface with local government and community members to translate this model into concrete conservation efforts.\nMy full analysis is available on RPubs:"
  },
  {
    "objectID": "posts/villa_del_rosario/index.html#pasos",
    "href": "posts/villa_del_rosario/index.html#pasos",
    "title": "Análisis de datos de incendios en Villa del Rosario",
    "section": "Pasos",
    "text": "Pasos\n\nInstalación de QGIS\n\nInstalar QGIS: Descargar e instalar desde https://qgis.org/download/\nInstalar complementos:\n\nAbrir QGIS → Complementos → Administrar e instalar complementos\nBuscar e instalar:\n\nQuickMapServices\nMapbiomas\nGoogle Earth Engine\n\n\nCrear conexiones WFS:\n\nIr a Capa → Agregar capa → Agregar capa WFS\nCrear nueva conexión:\n\nIGN:\n\nNombre: IGN\nURL: https://wms.ign.gob.ar/geoserver/ign/ows?version=1.0.0\nConectar y explorar capas disponibles\n\nIDECOR:\n\nNombre: IDECOR\nURL: https://idecor-ws.mapascordoba.gob.ar/geoserver/idecor/wfs\nConectar y explorar capas disponibles\n\n¡Agregar datos de incendios de IDECOR!\n\n\n\nGoogle Earth Engine\n\nCrear cuenta:\n\nIr a https://signup.earthengine.google.com/\nRegistrarse como cuenta de investigación o académica\nNota: Requiere cuenta de Gmail\n\nAutenticar en QGIS:\n\nAbrir QGIS\nIr a Complementos → Google Earth Engine\nSeleccionar “Autenticar”\nSe abrirá navegador para completar autenticación\nUna vez autenticado, el plugin estará listo para usar\n\n\n\n\nDescargar los siguientes datasets\n\nÁrea de interés (AOI):\n\nDescargar desde bucket AWS: poligonal_coovilros.geojson\nOpción alternativa: Cargar directamente desde HTTPS en QGIS (ver consola abajo)\n\nPérdida global de bosque por incendios:\n\nVersión pequeña (recomendada): bosque_perdido_a_fuego_2001-24.tif\nVersión completa (1.2GB): LAM_fire_forest_loss_2001-24.tif\nOpción alternativa: Cargar directamente desde HTTPS en QGIS (ver consola abajo)\n\nDatos Mapbiomas:\n\nIntentar obtener datos para Argentina vía plugin (2022, año más reciente)\nNota: El servidor WMS de Mapbiomas ha estado inestable últimamente\n\n\n\nRespaldo si Mapbiomas no funciona:\n\nDescargar datos:\n\nDescargar desde: suelo_2022.tif\nNombrar capa como suelo_2022\n\nEjecutar código de visualización:\n\n# Obtener la capa\nlayer = QgsProject.instance().mapLayersByName('suelo_2022')[0]\n\n# Crear entradas de clase individuales para cada valor de píxel\nclasses = [\n    QgsPalettedRasterRenderer.Class(3, QColor('#1f8d49'), 'Vegetación leñosa'),\n    QgsPalettedRasterRenderer.Class(4, QColor('#1f8d49'), 'Vegetación leñosa'),\n    QgsPalettedRasterRenderer.Class(45, QColor('#1f8d49'), 'Vegetación leñosa'),\n    QgsPalettedRasterRenderer.Class(6, QColor('#1f8d49'), 'Vegetación leñosa'),\n    QgsPalettedRasterRenderer.Class(11, QColor('#d6bc74'), 'Vegetación no leñosa'),\n    QgsPalettedRasterRenderer.Class(12, QColor('#d6bc74'), 'Vegetación no leñosa'),\n    QgsPalettedRasterRenderer.Class(63, QColor('#d6bc74'), 'Vegetación no leñosa'),\n    QgsPalettedRasterRenderer.Class(15, QColor('#ffefc3'), 'Área agropecuaria'),\n    QgsPalettedRasterRenderer.Class(18, QColor('#ffefc3'), 'Área agropecuaria'),\n    QgsPalettedRasterRenderer.Class(9, QColor('#ffefc3'), 'Área agropecuaria'),\n    QgsPalettedRasterRenderer.Class(36, QColor('#ffefc3'), 'Área agropecuaria'),\n    QgsPalettedRasterRenderer.Class(21, QColor('#ffefc3'), 'Área agropecuaria'),\n    QgsPalettedRasterRenderer.Class(22, QColor('#d4271e'), 'Área sin vegetación'),\n    QgsPalettedRasterRenderer.Class(33, QColor('#2532e3'), 'Cuerpo de agua'),\n    QgsPalettedRasterRenderer.Class(34, QColor('#2532e3'), 'Cuerpo de agua'),\n    QgsPalettedRasterRenderer.Class(27, QColor('#ffffff'), 'No observado')\n]\n\n# Crear renderizador con clases\nrenderer = QgsPalettedRasterRenderer(layer.dataProvider(), 1, classes)\n\n# Aplicar renderizador\nlayer.setRenderer(renderer)\nlayer.triggerRepaint()\n\n\n\nDatos de incendios MODIS/VIIRS procesados (Opción alternativa)\nSi no puedes configurar una cuenta de Google Earth Engine, puedes usar los datos de incendios ya procesados:\n\nDatos MODIS procesados:\n\nDescargar desde: MODIS procesado\nContiene todos los incendios MODIS detectados en el área de estudio (2000-2020)\n\nDatos VIIRS procesados:\n\nDescargar desde: VIIRS procesado\nContiene todos los incendios VIIRS detectados en el área de estudio (2012-2021)\n\nCargar en QGIS:\n\nDescargar ambos archivos GeoJSON\nEn QGIS: Capa → Agregar capa → Agregar capa vectorial\nSeleccionar los archivos descargados\nNombrar las capas como Incendios MODIS (2000-2020) y Incendios VIIRS (2012-2021)\n\n\nNota: Si usas estos datos procesados, puedes proceder directamente al Paso 4 (Preparar datos para agregación espacial y temporal) más abajo.\n\n\nMostrar cómo importar y analizar datos MODIS/VIIRS\n\nPasos para importar (acceso GEE)\n1. Instalar bibliotecas e inicializar Earth Engine: Primero necesitamos instalar geemap, una biblioteca de Python que facilita el trabajo con Google Earth Engine desde QGIS. También importamos todas las bibliotecas necesarias para el procesamiento de datos geoespaciales y inicializamos la conexión con Earth Engine.\n# Instalar geemap\nimport pip\npip.main(['install', 'geemap'])\n\n# Importar bibliotecas requeridas\nimport ee\nimport geemap\nfrom qgis.core import QgsProject, QgsVectorLayer\nimport pandas as pd\nimport geopandas as gpd\nfrom datetime import datetime\nfrom shapely import wkt\nimport processing\nimport tempfile\nimport os\n\n# Inicializar Earth Engine\nee.Initialize()\n2. Importar capas y datos de incendios: En este paso obtenemos nuestra capa de área de interés (AOI) desde QGIS y la convertimos a un formato compatible con Earth Engine. Luego definimos los años disponibles para MODIS (2000-2020) y VIIRS (2012-2021) y creamos una función para cargar los datos de incendios por año desde los datasets públicos de Earth Engine.\n# Obtener la capa AOI de QGIS\naoi_layer = QgsProject.instance().mapLayersByName('AOI')[0]\n\n# Convertir la capa QGIS a GeoDataFrame\nfeatures = [feat for feat in aoi_layer.getFeatures()]\ngeoms = [feat.geometry().asWkt() for feat in features]\n\ngeoms_shapely = [wkt.loads(geom) for geom in geoms]\naoi = gpd.GeoDataFrame({'geometry': geoms_shapely}, crs=aoi_layer.crs().authid())\n\n# Crear listas de todos los años disponibles\nmodis_years = list(range(2000, 2021))  # 2000-2020\nviirs_years = list(range(2012, 2022))  # 2012-2021\n\n# Función para crear FeatureCollection para un año y conjunto de datos específico\ndef crear_coleccion_incendios(conjunto_datos, año):\n    \"\"\"Crear un FeatureCollection para un conjunto de datos y año específico\"\"\"\n    if conjunto_datos == 'modis':\n        ruta = f\"projects/sat-io/open-datasets/MODIS_MCD14DL/MCD14DL_{año}\"\n    elif conjunto_datos == 'viirs':\n        ruta = f\"projects/sat-io/open-datasets/VIIRS/VNP14IMGTDL_NRT_{año}\"\n    else:\n        raise ValueError(\"El conjunto de datos debe ser 'modis' o 'viirs'\")\n    \n    try:\n        return ee.FeatureCollection(ruta)\n    except Exception as e:\n        print(f\"Advertencia: No se pudieron cargar los datos de {conjunto_datos} para el año {año}: {e}\")\n        return None\n\n# Cargar todos los datos MODIS (2000-2020)\nprint(\"Cargando datos MODIS (2000-2020)...\")\ncolecciones_modis = []\nfor año in modis_years:\n    coleccion = crear_coleccion_incendios('modis', año)\n    if coleccion is not None:\n        colecciones_modis.append(coleccion)\n\n# Cargar todos los datos VIIRS (2012-2021)\nprint(\"Cargando datos VIIRS (2012-2021)...\")\ncolecciones_viirs = []\nfor año in viirs_years:\n    coleccion = crear_coleccion_incendios('viirs', año)\n    if coleccion is not None:\n        colecciones_viirs.append(coleccion)\n\n# Combinar todas las colecciones en FeatureCollections únicas\nprint(\"Combinando todos los años...\")\ntodos_modis = ee.FeatureCollection(colecciones_modis).flatten()\ntodos_viirs = ee.FeatureCollection(colecciones_viirs).flatten()\n\n# Filtrar por área de interés\nee_aoi = geemap.geopandas_to_ee(aoi)\nprint(\"Filtrando por área de interés...\")\ntodos_modis_aoi = todos_modis.filterBounds(ee_aoi)\ntodos_viirs_aoi = todos_viirs.filterBounds(ee_aoi)\n\nprint(\"¡Procesamiento completo!\")\nprint(f\"Incendios MODIS en AOI: {todos_modis_aoi.size().getInfo()}\")\nprint(f\"Incendios VIIRS en AOI: {todos_viirs_aoi.size().getInfo()}\")\n3. Agregar datos MODIS/VIIRS al mapa: Una vez que hemos cargado y filtrado todos los datos de incendios por nuestra área de interés, los agregamos al mapa de QGIS. Esto nos permite visualizar todos los puntos de incendios detectados por ambos satélites en nuestro área de estudio.\n# Exportar a GeoJSON y agregar al mapa de QGIS\nprint(\"Exportando a archivos temporales y agregando al mapa...\")\n\n# Exportar MODIS\nmodis_temp = os.path.join(tempfile.gettempdir(), 'incendios_modis.geojson')\ngeemap.ee_to_geojson(todos_modis_aoi, modis_temp)\ncapa_modis = QgsVectorLayer(modis_temp, 'Incendios MODIS (2000-2020)', 'ogr')\nQgsProject.instance().addMapLayer(capa_modis)\n\n# Exportar VIIRS\nviirs_temp = os.path.join(tempfile.gettempdir(), 'incendios_viirs.geojson')\ngeemap.ee_to_geojson(todos_viirs_aoi, viirs_temp)\ncapa_viirs = QgsVectorLayer(viirs_temp, 'Incendios VIIRS (2012-2021)', 'ogr')\nQgsProject.instance().addMapLayer(capa_viirs)\n\nprint(\"¡Capas agregadas al mapa!\")\n\n\nPasos para analizar (cuadrícula hexagonal)\n4. Preparar datos para agregación espacial y temporal: Ahora necesitamos procesar los datos de incendios para poder analizarlos espacialmente. Extraemos solo la geometría y fecha de cada incendio, y los combinamos en un solo dataset. Luego agrupamos por geometría y mes para obtener observaciones únicas por mes, eliminando duplicados temporales.\n# Obtener las capas de incendios del proyecto QGIS\nprint(\"Obteniendo capas de incendios...\")\ncapa_modis = QgsProject.instance().mapLayersByName('Incendios MODIS (2000-2020)')[0]\ncapa_viirs = QgsProject.instance().mapLayersByName('Incendios VIIRS (2012-2021)')[0]\n\n# Convertir capas QGIS a GeoDataFrames con conversión de fechas\nprint(\"Convirtiendo capas a GeoDataFrames...\")\n\ndef qgis_to_gdf_with_dates(layer):\n    \"\"\"Convertir capa QGIS a GeoDataFrame con fechas correctamente formateadas\"\"\"\n    features = []\n    for f in layer.getFeatures():\n        attrs = dict(zip([field.name() for field in f.fields()], f.attributes()))\n        geom = f.geometry()\n        \n        # Convertir QDate a datetime de Python\n        if 'acq_date' in attrs:\n            qdate = attrs['acq_date']\n            if qdate is not None:\n                attrs['acq_date'] = datetime(qdate.year(), qdate.month(), qdate.day())\n        \n        attrs['geometry'] = wkt.loads(geom.asWkt())\n        features.append(attrs)\n    \n    gdf = gpd.GeoDataFrame(features, geometry='geometry', crs=layer.crs().authid())\n    return gdf\n\nmodis_gdf = qgis_to_gdf_with_dates(capa_modis)\nviirs_gdf = qgis_to_gdf_with_dates(capa_viirs)\n\n# Reproyectar a EPSG:5347\nmodis_gdf = modis_gdf.to_crs('EPSG:5347')\nviirs_gdf = viirs_gdf.to_crs('EPSG:5347')\n\n# 1. Extraer solo geometría y fecha de ambos gdfs\nprint(\"Extrayendo geometría y fecha de los datos MODIS...\")\nmodis_subset = modis_gdf[['geometry', 'acq_date']].copy()\nmodis_subset['source'] = 'MODIS'\n\nprint(\"Extrayendo geometría y fecha de los datos VIIRS...\")\nviirs_subset = viirs_gdf[['geometry', 'acq_date']].copy()\nviirs_subset['source'] = 'VIIRS'\n\n# 2. Concatenar en un solo dataframe\nprint(\"Concatenando dataframes...\")\ncombined_gdf = pd.concat([modis_subset, viirs_subset], ignore_index=True)\ncombined_gdf = gpd.GeoDataFrame(combined_gdf, geometry='geometry', crs='EPSG:5347')\n\n# 3. Extraer año-mes de acq_date y agrupar por geometría, año-mes\nprint(\"Procesando fechas y agrupando...\")\ncombined_gdf['acq_date'] = pd.to_datetime(combined_gdf['acq_date'])\ncombined_gdf['year_month'] = combined_gdf['acq_date'].dt.to_period('M')\n\n# Agrupar por geometría y año-mes para obtener observaciones únicas por mes\ngrouped = combined_gdf.groupby(['geometry', 'year_month']).size().reset_index(name='count')\ngrouped_gdf = gpd.GeoDataFrame(grouped, geometry='geometry', crs='EPSG:5347')\nprint(f\"Total de combinaciones únicas geometría-mes: {len(grouped_gdf)}\")\n5. Crear cuadrícula hexagonal de 1km (resolución máxima de MODIS): Para analizar los patrones espaciales de incendios, creamos una cuadrícula hexagonal de 1km de espaciado. Elegimos hexágonos porque proporcionan una mejor distribución espacial que cuadrados, y 1km porque es la resolución máxima de los datos MODIS. Esto significa que no podemos agregar a una escala menor sin perder precisión.\n# 4. Crear una cuadrícula hexagonal con 1km de espaciado usando QGIS\nprint(\"Creando cuadrícula hexagonal...\")\naoi_layer = QgsProject.instance().mapLayersByName('AOI')[0]\n\nhex_result = processing.run(\"native:creategrid\", {\n    'TYPE': 4,\n    'EXTENT': aoi_layer.extent(),\n    'HSPACING': 1000,\n    'VSPACING': 1000,\n    'HOVERLAY': 0,\n    'VOVERLAY': 0,\n    'CRS': aoi_layer.crs(),\n    'OUTPUT': 'memory:'\n})\n\nhex_layer = hex_result['OUTPUT']\nprint(f\"Creados {hex_layer.featureCount()} celdas hexagonales\")\n6. Unir observaciones a cuadrícula y contar: Finalmente, unimos nuestros puntos de incendios con la cuadrícula hexagonal usando operaciones espaciales. Contamos dos métricas importantes: el número de meses únicos con observaciones por hexágono (frecuencia temporal) y el número total de observaciones por hexágono (intensidad). Esto nos da una visión completa de los patrones de incendios en el espacio y tiempo.\n# Convertir capa hexagonal a GeoDataFrame\nhex_features = []\nfor f in hex_layer.getFeatures():\n    hex_features.append({'geometry': wkt.loads(f.geometry().asWkt())})\n\nhex_gdf = gpd.GeoDataFrame(hex_features, geometry='geometry', crs=hex_layer.crs().authid())\nhex_gdf = hex_gdf.to_crs('EPSG:5347')\nhex_gdf['cell_id'] = hex_gdf.index\n\n# 5. Contar número de meses por hexágono con al menos una observación\nprint(\"Contando meses por hexágono...\")\npoints_in_hex = gpd.sjoin(grouped_gdf, hex_gdf, how='left', predicate='within')\n\n# Contar meses únicos por hexágono\nmonths_per_hex = points_in_hex.groupby('cell_id')['year_month'].nunique().reset_index(name='meses_con_observaciones')\n\n# 6. Contar observaciones totales por hexágono\nprint(\"Contando observaciones totales por hexágono...\")\ntotal_obs_per_hex = points_in_hex.groupby('cell_id')['count'].sum().reset_index(name='observaciones_totales')\n\n# Combinar ambas métricas en un solo GeoDataFrame\nhex_final = hex_gdf.merge(months_per_hex, on='cell_id', how='left')\nhex_final = hex_final.merge(total_obs_per_hex, on='cell_id', how='left')\nhex_final['meses_con_observaciones'] = hex_final['meses_con_observaciones'].fillna(0)\nhex_final['observaciones_totales'] = hex_final['observaciones_totales'].fillna(0)\n\n# Guardar como capa temporal y agregar al mapa\nprint(\"Agregando cuadrícula hexagonal al mapa...\")\nhex_temp = os.path.join(tempfile.gettempdir(), 'cuadricula_hexagonal_incendios.geojson')\nhex_final.to_file(hex_temp, driver='GeoJSON')\nhex_final_layer = QgsVectorLayer(hex_temp, 'Cuadrícula Hexagonal - Incendios', 'ogr')\nQgsProject.instance().addMapLayer(hex_final_layer)\n\nprint(\"¡Agregación completada!\")\nprint(f\"Meses máximos con observaciones en un hexágono: {hex_final['meses_con_observaciones'].max()}\")\nprint(f\"Observaciones totales máximas en un hexágono: {hex_final['observaciones_totales'].max()}\")\n\n\n\nDashboard FIRMS\n\nExplorar dashboard\n\nExplicar qué pueden y no pueden hacer los datos\n\n\n\nConfigurar alertas para AOI subiendo archivo de límites"
  },
  {
    "objectID": "posts/wetland_change/index.html",
    "href": "posts/wetland_change/index.html",
    "title": "Wetland Change in Argentina",
    "section": "",
    "text": "For an independent study in applications of remote sensing for sustainable urban planning, I used Google Earth Engine and global wetlands datasets to train a Random Forest model on Landsat 7 spectral images and assess wetlands change from 2000 to 2020.\nMy model achieved 95% accuracy and 65% recall, and suggests that the Iberá wetlands have declined significantly in the past 20 years.\nHere, you can see my code in Google Colab:\n\n\n\nAdditionally, for a wetland ecology class, I put together a presentation on how remote sensing is used for wetland monitoring:"
  },
  {
    "objectID": "posts/dashboard/index.html",
    "href": "posts/dashboard/index.html",
    "title": "Clean & Green Philly",
    "section": "",
    "text": "Philadelphia has a gun violence problem. Through Code for Philly, I am leading a civic tech project that will help solve this problem by empowering community groups to carry out cleaning and greening interventions in the vacant properties where they can have the biggest impact. For this work, I was awarded the 2023 Witte-Sakamoto Family Prize in City Planning.\nExplore the live version of the dashboard here or read more about it in the PDF below."
  },
  {
    "objectID": "posts/eo_for_planning/index.html",
    "href": "posts/eo_for_planning/index.html",
    "title": "Remote Sensing for Urban Planning",
    "section": "",
    "text": "Based on an independent study that I did in remote sensing applications for urban planning, I gave a guest lecture to Penn’s graduate-level “deep learning applications for remote sensing” class. The lecture covered the basics of remote sensing, how remote sensing uses machine learning, and common applications of remote sensing for urban planning."
  },
  {
    "objectID": "posts/flood_prediction/index.html#overview",
    "href": "posts/flood_prediction/index.html#overview",
    "title": "Flood Prediction for Costa Rica",
    "section": "Overview",
    "text": "Overview\nAs part of a broader UN-Habitat initiative, I have been developing a methodology to predict urban flooding probabilities using open source remote sensing data and machine learning models in Google Earth Engine. This work will help urban planners in Costa Rica mitigate biodiversity loss due to urban and agricultural expansion.\n\n\n\nA raster map of flood probabilities across Costa Rica"
  },
  {
    "objectID": "posts/flood_prediction/index.html#data-and-model",
    "href": "posts/flood_prediction/index.html#data-and-model",
    "title": "Flood Prediction for Costa Rica",
    "section": "Data and Model",
    "text": "Data and Model\nThis work builds on a UN-Spider workflow that extracts flooding data for a given date, a paper on build a municipal flood index in Costa Rica, and two papers on building deep learning-based flood prediction models in Seoul and Brisbane. Data come via Google Earth Engine and are used to train a random forest model in Google Earth Engine via the Python API.\n\n\n \n\n  \n    \n      Powered by [Quarto](https://quarto.org)\n  \n       \n    \n      [Contact Me](mailto:nissimlebovits@proton.me)\n  \n    \n    \n      © 2025 Nissim Lebovits"
  },
  {
    "objectID": "posts/clean_and_green_oped/index.html",
    "href": "posts/clean_and_green_oped/index.html",
    "title": "Op Ed: Use Data for Better Cleaning and Greening",
    "section": "",
    "text": "In response to Mayor Cherelle Parker’s cleaning and greening initiatives in Philadelphia, I wrote an op ed in The Philadelphia Citizen calling on the Mayor to take a more data-driven approach:\n\n\n\n\n\n\n“Philadelphia’s quality of life issues are primarily concentrated in a handful of neighborhoods. For example, just 11.9 percent of Census blocks see all of Philly’s gun assaults. A mere 6.6 percent of blocks suffer nearly half the illegal dumping, while 27.7 percent of blocks account for all of the vacant buildings in Philadelphia. These challenges stem from decades of systemic disinvestment in marginalized neighborhoods, and disproportionately affect Black, Brown and low-income communities.\n\n\n~\n\n\n\n“Rather than just continuing with biannual cleanups of the entire city, Mayor Parker and the Office of Clean and Green Initiatives should prioritize additional monthly cleanups of the 1.5 percent of properties that have a disproportionately negative impact on quality of life for many of the Philadelphia most marginalized residents. By using data already available to them, the administration can strategically and proactively target the areas that most need support.”"
  },
  {
    "objectID": "posts/illegal_dumping/index.html",
    "href": "posts/illegal_dumping/index.html",
    "title": "Predicting Illegal Dumping",
    "section": "",
    "text": "Illegal dumping is a major problem in Philadelphia. Especially in low-income, minority neighborhoods, illegal dumping has a significant impact on quality of life, property values, safety, and public health. My interest in illegal dumping dates back to my AmeriCorps years with the city, and is something I’ve explored in other contexts, including for Clean & Green Philly and in my illegal dumping dashboard built in R with flexdashboard.\nFor one of my assignments in my “Public Policy Analytics” class at Penn, I built two Poisson regression-based predictive models to mitigate selection bias in illegal dumping prediction. I incorporated spatial processes into one of the models and evaluted one using spatial cross validation. However, I found that neither model represented an improvement over traditional kernel density estimate-based hotspot prediction.\nMy full analysis is available on RPubs:"
  },
  {
    "objectID": "posts/water_suppliers/index.html",
    "href": "posts/water_suppliers/index.html",
    "title": "Identifying Vulnerable Water Suppliers",
    "section": "",
    "text": "As a research assistant for Professor Allison Lassiter, I work on assessing the vulnerability of U.S. coastal drinking water suppliers to climate change. We consider financial, physical, and climatic dimensions of vulnerability and are applying various clustering models to them, such as k-means clustering and Gaussian mixture modeling. We hope that this work will eventually inform a Robert Wood Johnson Foundation effort to direct funding to underserved and overburdened water suppliers.\nForthcoming, “Which water suppliers are underserved and overburdened? A multidimensional classification of vulnerability under climate stress,” Allison Lassiter, Nissim Lebovits, Zoe Kerrich, and Henry Feinstein."
  },
  {
    "objectID": "posts/gee_presentation/index.html",
    "href": "posts/gee_presentation/index.html",
    "title": "Google Earth Engine for Urban Planning",
    "section": "",
    "text": "Based on my work in Google Earth Engine for a UN-Habitat project, I gave a guest lecture to Penn’s graduate-level “deep learning applications for remote sensing” class. The lecture covered the basics of Google Earth Engine; several examples of using GEE in JavaScript and Python for flood detection, land surface temperature mapping, and land cover classification; ways to extend GEE’s functionality; and resources for learning GEE."
  }
]